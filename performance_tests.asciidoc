== Stress Tests and Performance Tests

WARNING: This chapter is a work in progress, examples and the like
will be added

Unit tests are great in that they tell you if your code is working
correctly. They are also nice in that a new team member can look at a
result of a unit test run and know if the tests passed or failed.

Performance testing is a whole different thing. While Unit tests are
binary in their results (pass or fail) a performance test is very much
analogy. If I tell you that a system can handle "5,000 concurrent users
with a mean response time of 145ms+/- 32ms on an Amazon EC2 Large
Instance" (Assume numbers in this chapter are completely
made up unless noted otherwise.) is that good or bad?
It would be impossible to tell without a detailed understanding of the
goals of the system. However understanding how a system will perform
under load is an essential part of any system that will be deployed.

At some point the developers of a system will have to turn it over to
an operations team and they will need to do things like determine how
many servers are needed to support the expected load of customers.

TIP: It is important to simulate a realistic workload

It is very easy to create a set of tests that will produce a lot of
pretty graphs but will be totally useless for figuring out how to meet
the actual needs of your system. For example you could use a tool like
link:http://httpd.apache.org/docs/2.2/programs/ab.html[Apache Bench]
you could find out how many static html pages you can server per
minute. This is probably not useful. For one thing you are much better
off putting your static files on a CDN and letting Akamai or Amazon
server them for you.

What you need is to understand what kinds of dynamic content will be
served and where possible bottlenecks are. For example if you are
building a pub/sub server you will probably want to monitor how fast
you can add users to the system and how fast you can deliver messages
to those users.

TIP: Change one thing at a time

Most applications have a lot of possible places where configurations
can be changed, pool sizes, memory usage, server instance sizes and so
on. It is very important to only make one change between each test
run. If you change several things then you will find that you are
unable to figure out which change you made actually caused the changes
that you are seeing. Or even that the two changes interacted with each
other in some strange way.

Of course this does not mean that you can not try several things in
parallel simply by bringing up more servers if you are running in a
cloud setting.

TIP: Keep good notes

Use a blog, a wiki or a git commit log, but keep notes on what you did
and what the results of each step are. This will help you to
understand where issues are and in six months when you have to do some
more performance tuning it will be good to be able to review what you
have already done.

TIP: Don't Optimize past the business needs.

At some point a server is optimized enough. That does not mean that it
can not be optimized more, or that you will not come back to this in 6
months to improve things, but if you reach a level where you can
support the workload then stop.

TIP: A larger server may be cheaper than programmer time

It may be the case that going up one size on your server nodes, or adding a few
more servers will be cheaper and easier than having a programmer spend
a week finding the next bottleneck.

=== Finding the bottlenecks

NOTE: This section needs work

Of course the only way to actually find the bottlenecks in code is to
run it under load and wait for things to break. Thankfully Erlang
provides a number of tools for doing that.

There are a number of ways for a system to get slowed down. It could
be bound by disk or Network IO, which could be a database or an
external service.

However another place that things could be bottle-necked is by a
single named process being overloaded. In that case what will happen
is that the processes message queue will start to backup.

Here is where http://en.wikipedia.org/wiki/Amdahl's_law[Amdahl's law]
comes into play. Amdahl's law states that in a parallel system the
most speed-up that can be had by creating more processes is limited by
the sequential parts of the problem.


If a process is bottle necking your system its message queue size will
start to grow as messages arrive faster than they can be handled. The
size of the message queue can be seen by using the +process_info/2+
NIF.


First of all if you are using gen_servers make sure you are sending
them messages with a timeout set, that way if something gets slowed
down eventually they will start to die en mass and you will know that
something is wrong.


If you call +process_info(Pid, message_queue_len)+ it will return
+{message_queue_len,Length}+. (You can also see the messages if you
want). In general you may suspect that your code is running slowly
because a process is falling behind its messages, but of course you
want to know for sure.

Erlang does not provide a built in way to monitor queue lengths
so some form of polling is required. What would be nice is being able
to come up with a list of processes to monitor and have them all
polled periodically. If the message queue of any process goes over
some pre-determined threshold the monitor will take some form of
action, such as writing an entry to a log.

If you find that a process is backing up then you probably want to
turn it into a pool, with something like
https://github.com/devinus/poolboy[Poolboy]